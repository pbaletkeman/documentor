{
  "llm_models": [
    {
      "name": "llama3.2",
      "provider": "ollama",
      "baseUrl": "http://localhost:11434",
      "apiKey": "",
      "maxTokens": 4096,
      "timeoutSeconds": 60
    },
    {
      "name": "llamacpp",
      "provider": "llamacpp",
      "baseUrl": "http://localhost:8080",
      "apiKey": "",
      "maxTokens": 2048,
      "timeoutSeconds": 90
    },
    {
      "name": "codellama",
      "provider": "ollama",
      "baseUrl": "http://localhost:11434",
      "apiKey": "",
      "maxTokens": 4096,
      "timeoutSeconds": 60
    },
    {
      "name": "gpt-3.5-turbo",
      "provider": "openai",
      "baseUrl": "https://api.openai.com/v1/chat/completions",
      "apiKey": "your-openai-api-key-here",
      "maxTokens": 4096,
      "timeoutSeconds": 30
    },
    {
      "name": "gpt-4",
      "provider": "openai",
      "baseUrl": "https://api.openai.com/v1/chat/completions",
      "apiKey": "your-openai-api-key-here",
      "maxTokens": 8192,
      "timeoutSeconds": 60
    }
  ],
  "output_settings": {
    "output_directory": "./docs",
    "format": "markdown",
    "include_icons": true,
    "generate_unit_tests": true,
    "run_unit_test_commands": false,
    "log_unit_test_commands": true,
    "target_coverage": 0.9,
    "generate_mermaid": false,
    "generate_plantuml": false,
    "verbose_output": false
  },
  "analysis_settings": {
    "include_private_members": false,
    "max_threads": 4,
    "supported_languages": [
      "java",
      "python"
    ],
    "exclude_patterns": [
      "**/test/**",
      "**/target/**",
      "**/__pycache__/**",
      "**/node_modules/**",
      "**/.git/**",
      "**/build/**",
      "**/.idea/**",
      "**/.vscode/**"
    ]
  }
}
