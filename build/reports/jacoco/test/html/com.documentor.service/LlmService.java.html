<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>LlmService.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">documentor</a> &gt; <a href="index.source.html" class="el_package">com.documentor.service</a> &gt; <span class="el_source">LlmService.java</span></div><h1>LlmService.java</h1><pre class="source lang-java linenums">package com.documentor.service;

import com.documentor.config.DocumentorConfig;
import com.documentor.model.CodeElement;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import org.springframework.web.reactive.function.client.WebClient;

import java.time.Duration;
import java.util.List;
import java.util.Map;
import java.util.concurrent.CompletableFuture;

/**
 * ü§ñ LLM Integration Service
 * 
 * Handles communication with Large Language Models to generate:
 * - Code summaries and documentation
 * - Usage examples with sample data
 * - Unit test suggestions
 */
@Service
public class LlmService {

<span class="fc" id="L29">    private static final Logger logger = LoggerFactory.getLogger(LlmService.class);</span>

    private final DocumentorConfig config;
    private final WebClient webClient;
    private final ObjectMapper objectMapper;

<span class="fc" id="L35">    public LlmService(DocumentorConfig config, WebClient webClient) {</span>
<span class="fc" id="L36">        this.config = config;</span>
<span class="fc" id="L37">        this.webClient = webClient;</span>
<span class="fc" id="L38">        this.objectMapper = new ObjectMapper();</span>
<span class="fc" id="L39">    }</span>

    /**
     * üìù Generates documentation for a code element using multiple LLM models
     * 
     * @param codeElement The code element to document
     * @return CompletableFuture containing the generated documentation
     */
    @Async(&quot;llmExecutor&quot;)
    public CompletableFuture&lt;String&gt; generateDocumentation(CodeElement codeElement) {
<span class="fc" id="L49">        logger.debug(&quot;ü§ñ Generating documentation for: {}&quot;, codeElement.getDisplayName());</span>

<span class="fc" id="L51">        List&lt;CompletableFuture&lt;String&gt;&gt; futures = config.llmModels().stream()</span>
<span class="fc" id="L52">                .map(model -&gt; generateWithModel(codeElement, model))</span>
<span class="fc" id="L53">                .map(CompletableFuture::completedFuture)</span>
<span class="fc" id="L54">                .toList();</span>

<span class="fc" id="L56">        return CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))</span>
<span class="fc" id="L57">                .thenApply(v -&gt; {</span>
<span class="fc" id="L58">                    List&lt;String&gt; responses = futures.stream()</span>
<span class="fc" id="L59">                            .map(CompletableFuture::join)</span>
<span class="pc bpc" id="L60" title="1 of 2 branches missed.">                            .filter(response -&gt; !response.isEmpty())</span>
<span class="fc" id="L61">                            .toList();</span>
                    
<span class="fc" id="L63">                    return consolidateResponses(responses, codeElement);</span>
                });
    }

    /**
     * üí° Generates usage examples for a code element
     */
    @Async(&quot;llmExecutor&quot;)
    public CompletableFuture&lt;String&gt; generateUsageExamples(CodeElement codeElement) {
<span class="fc" id="L72">        logger.debug(&quot;üí° Generating usage examples for: {}&quot;, codeElement.getDisplayName());</span>

<span class="fc" id="L74">        String prompt = createUsageExamplePrompt(codeElement);</span>
        
        // Use the first available model for examples
<span class="fc bfc" id="L77" title="All 2 branches covered.">        if (!config.llmModels().isEmpty()) {</span>
<span class="fc" id="L78">            DocumentorConfig.LlmModelConfig model = config.llmModels().get(0);</span>
<span class="fc" id="L79">            return CompletableFuture.completedFuture(callLlmModel(model, prompt));</span>
        }
        
<span class="fc" id="L82">        return CompletableFuture.completedFuture(&quot;No LLM models configured for usage examples.&quot;);</span>
    }

    /**
     * üß™ Generates unit test suggestions for a code element
     */
    @Async(&quot;llmExecutor&quot;)
    public CompletableFuture&lt;String&gt; generateUnitTests(CodeElement codeElement) {
<span class="fc" id="L90">        logger.debug(&quot;üß™ Generating unit tests for: {}&quot;, codeElement.getDisplayName());</span>

<span class="fc" id="L92">        String prompt = createUnitTestPrompt(codeElement);</span>
        
        // Use the first available model for unit tests
<span class="fc bfc" id="L95" title="All 2 branches covered.">        if (!config.llmModels().isEmpty()) {</span>
<span class="fc" id="L96">            DocumentorConfig.LlmModelConfig model = config.llmModels().get(0);</span>
<span class="fc" id="L97">            return CompletableFuture.completedFuture(callLlmModel(model, prompt));</span>
        }
        
<span class="fc" id="L100">        return CompletableFuture.completedFuture(&quot;No LLM models configured for unit test generation.&quot;);</span>
    }

    /**
     * üîÑ Generates documentation using a specific LLM model
     */
    private String generateWithModel(CodeElement codeElement, DocumentorConfig.LlmModelConfig model) {
        try {
<span class="fc" id="L108">            String prompt = createDocumentationPrompt(codeElement);</span>
<span class="fc" id="L109">            return callLlmModel(model, prompt);</span>
<span class="nc" id="L110">        } catch (Exception e) {</span>
<span class="nc" id="L111">            logger.error(&quot;‚ùå Error generating documentation with model {}: {}&quot;, model.name(), e.getMessage());</span>
<span class="nc" id="L112">            return &quot;&quot;;</span>
        }
    }

    /**
     * üìû Makes API call to LLM model
     */
    private String callLlmModel(DocumentorConfig.LlmModelConfig model, String prompt) {
        try {
<span class="fc" id="L121">            Map&lt;String, Object&gt; requestBody = createRequestBody(model, prompt);</span>
<span class="fc" id="L122">            String endpoint = getModelEndpoint(model);</span>

<span class="fc" id="L124">            String response = webClient.post()</span>
<span class="nc" id="L125">                    .uri(endpoint)</span>
<span class="nc" id="L126">                    .header(&quot;Authorization&quot;, &quot;Bearer &quot; + model.apiKey())</span>
<span class="nc" id="L127">                    .header(&quot;Content-Type&quot;, &quot;application/json&quot;)</span>
<span class="nc" id="L128">                    .bodyValue(requestBody)</span>
<span class="nc" id="L129">                    .retrieve()</span>
<span class="nc" id="L130">                    .bodyToMono(String.class)</span>
<span class="nc" id="L131">                    .timeout(Duration.ofSeconds(model.timeoutSeconds()))</span>
<span class="nc" id="L132">                    .block();</span>

<span class="nc" id="L134">            return extractResponseContent(response, model);</span>

<span class="fc" id="L136">        } catch (Exception e) {</span>
<span class="fc" id="L137">            logger.error(&quot;‚ùå LLM API call failed for model {}: {}&quot;, model.name(), e.getMessage());</span>
<span class="fc" id="L138">            return &quot;Error generating content with &quot; + model.name();</span>
        }
    }

    /**
     * üèóÔ∏è Creates request body for LLM API call
     */
    private Map&lt;String, Object&gt; createRequestBody(DocumentorConfig.LlmModelConfig model, String prompt) {
<span class="fc" id="L146">        return Map.of(</span>
<span class="fc" id="L147">            &quot;model&quot;, model.name(),</span>
<span class="fc" id="L148">            &quot;messages&quot;, List.of(</span>
<span class="fc" id="L149">                Map.of(&quot;role&quot;, &quot;system&quot;, &quot;content&quot;, &quot;You are a helpful code documentation assistant.&quot;),</span>
<span class="fc" id="L150">                Map.of(&quot;role&quot;, &quot;user&quot;, &quot;content&quot;, prompt)</span>
            ),
<span class="fc" id="L152">            &quot;max_tokens&quot;, model.maxTokens(),</span>
<span class="fc" id="L153">            &quot;temperature&quot;, model.temperature()</span>
        );
    }

    /**
     * üåê Gets the appropriate endpoint for the model
     */
    private String getModelEndpoint(DocumentorConfig.LlmModelConfig model) {
<span class="pc bpc" id="L161" title="2 of 4 branches missed.">        if (model.endpoint() != null &amp;&amp; !model.endpoint().isEmpty()) {</span>
<span class="fc" id="L162">            return model.endpoint();</span>
        }
        
        // Default endpoints based on model names
<span class="nc bnc" id="L166" title="All 2 branches missed.">        if (model.name().startsWith(&quot;gpt-&quot;)) {</span>
<span class="nc" id="L167">            return &quot;https://api.openai.com/v1/chat/completions&quot;;</span>
<span class="nc bnc" id="L168" title="All 2 branches missed.">        } else if (model.name().startsWith(&quot;claude-&quot;)) {</span>
<span class="nc" id="L169">            return &quot;https://api.anthropic.com/v1/messages&quot;;</span>
        }
        
<span class="nc" id="L172">        throw new IllegalArgumentException(&quot;No endpoint configured for model: &quot; + model.name());</span>
    }

    /**
     * üì§ Extracts content from LLM response
     */
    private String extractResponseContent(String response, DocumentorConfig.LlmModelConfig model) {
        try {
<span class="nc" id="L180">            JsonNode jsonNode = objectMapper.readTree(response);</span>
            
            // OpenAI format
<span class="nc bnc" id="L183" title="All 2 branches missed.">            if (jsonNode.has(&quot;choices&quot;)) {</span>
<span class="nc" id="L184">                return jsonNode.get(&quot;choices&quot;).get(0).get(&quot;message&quot;).get(&quot;content&quot;).asText();</span>
            }
            
            // Anthropic format
<span class="nc bnc" id="L188" title="All 2 branches missed.">            if (jsonNode.has(&quot;content&quot;)) {</span>
<span class="nc" id="L189">                return jsonNode.get(&quot;content&quot;).get(0).get(&quot;text&quot;).asText();</span>
            }
            
<span class="nc" id="L192">            return &quot;Unable to parse response from &quot; + model.name();</span>
            
<span class="nc" id="L194">        } catch (Exception e) {</span>
<span class="nc" id="L195">            logger.error(&quot;‚ùå Error parsing LLM response: {}&quot;, e.getMessage());</span>
<span class="nc" id="L196">            return &quot;Error parsing response from &quot; + model.name();</span>
        }
    }

    /**
     * üîó Consolidates multiple LLM responses into a single documentation
     */
    private String consolidateResponses(List&lt;String&gt; responses, CodeElement codeElement) {
<span class="fc bfc" id="L204" title="All 2 branches covered.">        if (responses.isEmpty()) {</span>
<span class="fc" id="L205">            return &quot;No documentation generated.&quot;;</span>
        }
        
<span class="fc bfc" id="L208" title="All 2 branches covered.">        if (responses.size() == 1) {</span>
<span class="fc" id="L209">            return responses.get(0);</span>
        }
        
        // Simple consolidation - take the longest response as primary
        // In a real implementation, you might use another LLM call to merge responses
<span class="fc" id="L214">        return responses.stream()</span>
<span class="fc" id="L215">                .max((a, b) -&gt; Integer.compare(a.length(), b.length()))</span>
<span class="fc" id="L216">                .orElse(&quot;No documentation generated.&quot;);</span>
    }

    /**
     * üìù Creates documentation generation prompt
     */
    private String createDocumentationPrompt(CodeElement codeElement) {
<span class="fc" id="L223">        return String.format(&quot;&quot;&quot;</span>
            Please generate comprehensive documentation for the following %s:
            
            %s
            
            Please provide:
            1. A clear description of what this %s does
            2. Parameters explanation (if applicable)
            3. Return value description (if applicable)
            4. Any important notes or considerations
            5. Brief usage context
            
            Format the response in markdown.
            &quot;&quot;&quot;, 
<span class="fc" id="L237">            codeElement.type().getDescription().toLowerCase(),</span>
<span class="fc" id="L238">            codeElement.getAnalysisContext(),</span>
<span class="fc" id="L239">            codeElement.type().getDescription().toLowerCase()</span>
        );
    }

    /**
     * üí° Creates usage example generation prompt
     */
    private String createUsageExamplePrompt(CodeElement codeElement) {
<span class="fc" id="L247">        return String.format(&quot;&quot;&quot;</span>
            Please generate practical usage examples for the following %s:
            
            %s
            
            Please provide:
            1. 2-3 realistic usage examples with sample data
            2. Expected outputs or results
            3. Common use cases
            4. Best practices for usage
            
            Use realistic sample data and format the response in markdown with code blocks.
            &quot;&quot;&quot;, 
<span class="fc" id="L260">            codeElement.type().getDescription().toLowerCase(),</span>
<span class="fc" id="L261">            codeElement.getAnalysisContext()</span>
        );
    }

    /**
     * üß™ Creates unit test generation prompt
     */
    private String createUnitTestPrompt(CodeElement codeElement) {
<span class="fc" id="L269">        return String.format(&quot;&quot;&quot;</span>
            Please generate comprehensive unit tests for the following %s:
            
            %s
            
            Please provide:
            1. Test cases for normal operation
            2. Edge cases and boundary conditions
            3. Error handling tests
            4. Mock objects if needed
            5. Aim for high code coverage
            
            Use appropriate testing framework (JUnit for Java, pytest for Python) and format as code blocks.
            &quot;&quot;&quot;, 
<span class="fc" id="L283">            codeElement.type().getDescription().toLowerCase(),</span>
<span class="fc" id="L284">            codeElement.getAnalysisContext()</span>
        );
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.9.202303310957</span></div></body></html>